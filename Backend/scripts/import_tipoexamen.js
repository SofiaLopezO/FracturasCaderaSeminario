#!/usr/bin/env node
/**
 * Importa TIPOEXAMEN.csv a public.tipo_examen (UPSERT por id o insert por nombre).
 * Columnas esperadas: id, nombre, descripcion (en cualquier orden)
 * Uso:
 *   node scripts/import_tipoexamen.js ./scripts/TIPOEXAMEN.csv --preview
 *   node scripts/import_tipoexamen.js ./scripts/TIPOEXAMEN.csv
 */
const fs = require("fs");
const path = require("path");
const { Pool } = require("pg");
const { parse } = require("csv-parse/sync");
const iconv = require("iconv-lite");

require("dotenv").config({ path: path.resolve(process.cwd(), ".env") });

const {
  PGHOST = "localhost",
  PGPORT = "5432",
  PGDATABASE = "fracturas",
  PGUSER = "sofia",
  PGPASSWORD = "Clave1234",
} = process.env;

const INPUT = process.argv[2] || path.resolve(process.cwd(), "scripts", "TIPOEXAMEN.csv");
const SCHEMA = "public";
const TABLE = "tipo_examen";
const FQ = `${SCHEMA}.${TABLE}`;
const PREVIEW = process.argv.includes("--preview");

/* ---------- helpers CSV/encoding ---------- */
const deBOM = (s) => (s && s.charCodeAt(0) === 65279 ? s.slice(1) : s);
function detectDelimiter(firstLine) {
  const count = (ch) => (firstLine.match(new RegExp(`\\${ch}`, "g")) || []).length;
  return count(";") > count(",") ? ";" : ",";
}
function decodeBest(buf) {
  const cands = ["utf8", "win1252", "latin1"];
  let best = { text: "", score: -Infinity };
  for (const enc of cands) {
    const text = iconv.decode(buf, enc);
    const repl = (text.match(/\uFFFD/g) || []).length;
    const mojis = (text.match(/Ã.|Â.|ï../g) || []).length;
    const score = -repl - mojis;
    if (score > best.score) best = { text, score };
  }
  return best.text;
}
function readCSVFlexible(filePath) {
  const buf = fs.readFileSync(filePath);
  const txt = decodeBest(buf);
  const first = (txt.split(/\r?\n/)[0] || "").trim();
  const delimiter = detectDelimiter(first);
  const rows = parse(txt, {
    columns: (h) => h.map((x) => deBOM(String(x).trim().toLowerCase())),
    bom: true,
    skip_empty_lines: true,
    relax_column_count: true,
    trim: true,
    delimiter,
  });
  return rows;
}

/* ---------- normalización ---------- */
function mapRow(r) {
  const obj = {};
  for (const [k, v] of Object.entries(r)) obj[String(k).trim().toLowerCase()] = v;
  const id = obj.id === "" || obj.id == null ? null : Number(obj.id);
  const nombre = String(obj.nombre ?? "").trim();
  const descripcion = String(obj.descripcion ?? "").trim();
  return { id, nombre, descripcion };
}

/* ---------- garantías de esquema ---------- */
async function ensurePrimaryKeyAndIdentity(cx) {
  // PK en id
  const pk = await cx.query(
    `
    SELECT 1
    FROM pg_constraint c
    JOIN pg_class t ON t.oid = c.conrelid
    JOIN pg_namespace n ON n.oid = t.relnamespace
    WHERE c.contype = 'p'
      AND n.nspname = $1
      AND t.relname = $2
  `,
    [SCHEMA, TABLE]
  );
  if (pk.rowCount === 0) {
    await cx.query(`ALTER TABLE ${FQ} ADD PRIMARY KEY (id)`);
  }
  // default autoincrement (identity o secuencia)
  const def = await cx.query(
    `
    SELECT 1
    FROM information_schema.columns
    WHERE table_schema = $1 AND table_name = $2
      AND column_name = 'id'
      AND (column_default IS NOT NULL OR is_identity = 'YES')
  `,
    [SCHEMA, TABLE]
  );
  if (def.rowCount === 0) {
    await cx.query(`ALTER TABLE ${FQ} ALTER COLUMN id ADD GENERATED BY DEFAULT AS IDENTITY`);
  }
}

async function ensureUniqueNombre(cx) {
  const uniq = await cx.query(
    `
    SELECT 1
    FROM pg_index i
    JOIN pg_class t ON t.oid = i.indrelid
    JOIN pg_namespace n ON n.oid = t.relnamespace
    WHERE n.nspname = $1 AND t.relname = $2
      AND i.indisunique = true
      AND EXISTS (
        SELECT 1
        FROM pg_attribute a
        WHERE a.attrelid = t.oid
          AND a.attnum = ANY(i.indkey)
          AND a.attname = 'nombre'
      )
  `,
    [SCHEMA, TABLE]
  );
  if (uniq.rowCount === 0) {
    await cx.query(`CREATE UNIQUE INDEX IF NOT EXISTS ux_${TABLE}_nombre ON ${FQ} (nombre)`);
  }
}

/* ---------- main ---------- */
(async () => {
  console.log(`Archivo: ${INPUT}`);
  const pool = new Pool({
    host: PGHOST,
    port: Number(PGPORT),
    database: PGDATABASE,
    user: PGUSER,
    password: PGPASSWORD,
  });
  const cx = await pool.connect();

  try {
    // Si la conexión del pool viniera "aborted" por un uso previo, esto la limpia sin fallar
    try { await cx.query("ROLLBACK"); } catch (_) {}

    // DDL en su propia transacción (no usar SAVEPOINT fuera de BEGIN)
    await cx.query("BEGIN");
    await ensurePrimaryKeyAndIdentity(cx);
    await ensureUniqueNombre(cx);
    await cx.query("COMMIT");

    const raw = readCSVFlexible(INPUT);
    const rows = raw.map(mapRow).filter((r) => r.nombre);
    console.log(`Filas leídas: ${rows.length}`);

    if (PREVIEW) {
      console.log(rows.slice(0, 5));
      return;
    }

    // Import en transacción
    await cx.query("BEGIN");

    const upsertById = `
      INSERT INTO ${FQ} (id, nombre, descripcion)
      VALUES ($1, $2, $3)
      ON CONFLICT (id) DO UPDATE
      SET nombre = EXCLUDED.nombre,
          descripcion = EXCLUDED.descripcion
    `;

    let ok = 0, bad = 0;
    for (const r of rows) {
      try {
        if (r.id == null) {
          await cx.query(
            `INSERT INTO ${FQ} (nombre, descripcion)
             VALUES ($1,$2)
             ON CONFLICT (nombre) DO NOTHING`,
            [r.nombre, r.descripcion || null]
          );
        } else {
          await cx.query(upsertById, [r.id, r.nombre, r.descripcion || null]);
        }
        ok++;
      } catch (e) {
        bad++;
        console.error(`Error registro id=${r.id ?? "(auto)"}: ${e.message}`);
      }
    }

    await cx.query("COMMIT");
    console.log(`Importación tipo_examen: OK=${ok}  Errores=${bad}`);
  } catch (err) {
    try { await cx.query("ROLLBACK"); } catch (_) {}
    console.error("Fallo general:", err.message);
    process.exit(1);
  } finally {
    cx.release();
    await pool.end();
  }
})();
